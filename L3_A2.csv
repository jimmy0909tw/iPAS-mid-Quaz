題號,難度,題目,選項 1,選項 2,選項 3,選項 4,正確答案,正確答案解說,錯誤答案解說
L3QA117,S,"一個連續隨機變數 X 服從常態分佈 N(100,16)。則 X 落在區間 96 到 104的機率最接近哪一個值？",34%,68%,95%,99.7%,2,此區間為 μ ± 2σ = 100 ± 4，屬於 ±1σ 內，約為 68%。,
L3QA118,S,某疾病盛行率為 1%，檢測靈敏度為 99%，偽陽性率為 5%。若某人檢測陽性，其實際患病機率為？,約 16%,約 50%,約 75%,約 99%,1,使用貝氏定理計算：P(病|陽) = (0.99×0.01)/(0.99×0.01 + 0.05×0.99) ? 0.166 這一題是經典的 貝式定理（Bayes' Theorem） 應用題，出現在醫學檢測、機器學習、甚至是 AI 證照中都非常常見。,
L3QA119,S,若母體為高度偏斜分佈，從中抽樣 n=100 計算樣本平均，其分佈趨近：,原始母體,均勻分佈,常態分佈,貝他分佈,3,中心極限定理成立，樣本平均近似常態分佈。,
L3QA120,S,若 Var(X) = 9，則 Var(2X + 5) 為？,9,18,36,49,3,Var(aX + b) = a? Var(X)，所以 = 4×9 = 36,
L3QA121,S,樣本平均為 80，標準誤為 2，信心水準為 95%，信賴區間為？,76 ~ 84,78 ~ 82,79 ~ 81,77.5 ~ 82.5,1,"CI = 80 ± 1.96×2 ? [76.08, 83.92]",
L3QA122,S,某檢定的 p 值為 0.08，顯著水準為 0.05，應採取何種結論？,拒絕 H?,接受 H?,不拒絕 H?,接受 H?,3,p > α，故不拒絕 H?。,
L3QA123,S,在 Naive Bayes 中，條件獨立假設代表什麼？,特徵間完全獨立,特徵對目標變數獨立,特徵在同一類別下互不影響,每個特徵都有相同權重,3,核心假設為在同一類別 C 下，各特徵條件獨立。,
L3QA124,S,若某連續特徵符合常態分佈，GNB 如何處理？,離散化,分箱,使用高斯機率密度函數,忽略該特徵,3,對連續變數，使用高斯分佈來估條件機率,
L3QA125,S,若模型預測為 0.99，實際標籤為 0，則交叉熵為？,趨近 0,介於 0.5~1,趨近 ∞,無法判斷,3,log(1 ? 0.99) → log(0.01) = 4.6，loss 非常大。,
L3QA126,S,PCA 的第一主成分是？,所有特徵的平均,最大變異方向,最小誤差方向,類別分界線,2,主成分是資料在變異數最大的方向。,
L3QA127,S,哪個方法將資料轉為均值為 0，標準差為 1？,Scaling,Normalization,Standardization,PCA,3,Z-score 標準化屬於 standardization。,
L3QA128,S,Precision 的計算公式為？,TP / (TP + FN),TP / (TP + FP),TP / (TP + TN),(TP + TN)/Total,2,Precision 是「預測為正的，有多少是真正的」。,
L3QA129,S,ROC 曲線的 x 軸代表？,Accuracy,Recall,False Positive Rate,Specificity,3,ROC 的 x 軸是 FPR（1?Specificity）。,
L3QA130,S,一份分類模型在樣本不平衡下（正例 1%，負例 99%）得到 99% accuracy，最有可能代表：,模型表現極佳,模型只有 Recall 不佳,模型幾乎全預測為負類,模型被過擬合,3,全預測為負類也能有 99% accuracy → 模型未學習到真正正例。,
L3QA131,S,PCA 前需進行什麼處理以避免尺度問題？,One-hot encoding,標準化,決策樹剪枝,Normalization,2,PCA 對尺度敏感，需標準化每一特徵。,
L3QA132,S,下列關於 PCA 的敘述何者錯誤？,PCA 是一種常用的特徵降維方法,PCA 能提高模型準確率，一定能提升效能,PCA 的第一主成分代表最大變異方向,PCA 前須進行特徵標準化,2,PCA 是降維工具，不保證一定提升模型效能，有時反而會損失關鍵資訊，A/C/D 正確。,
L3QA133,S,在推薦系統中，使用者的喜好向量為 ，商品特徵向量為  。請問內積  結果為何？,2,4,5,7,2,使用內積公式：,
L3QA134,S,若 為 3x2 矩陣，則  的維度為何？,2x2,2x3,3x3,3x2,2,,
L3QA135,S,主成分分析（PCA）主要依賴哪一種數學工具來找資料的主軸方向？,特徵值分解,QR 分解,LU 分解,轉置運算,1,PCA 是針對資料的共變異矩陣進行特徵值分解，保留主要方向。 PCA 運用共變異矩陣 ，進行特徵值分解，保留最大特徵值對應方向以降維。,
L3QA136,S,若向量，其範數（模）為多少？,5,7,12,25,1,,
L3QA137,S,一筆資料為 ，權重為 ，請問預測值  為何？,3.0,3.4,3.8,4.2,3,,
L3QA138,S,機器學習常用矩陣計算的主要原因為何？,可以直接求解常數,方便資料清理,符合圖像格式,可處理大量資料並提升計算效率,4,矩陣計算可進行向量化與批次運算，極大提升效率（尤其在 GPU 上）。,
L3QA139,S,學習率在優化過程中扮演的主要角色是什麼？,決定模型輸出範圍,控制每次梯度更新的步伐大小,控制激活函數的形狀,計算模型的損失值,2,學習率是控制參數更新幅度的超參數，與梯度方向一起決定模型如何靠近最小值。,
L3QA140,S,一位資料科學家發現模型的 loss 在訓練過程中來回震盪，始終無法穩定下降。最可能的原因是？,模型太簡單,資料未正規化,學習率過高,選錯損失函數,3,震盪代表每次步伐太大，可能錯過最佳點或不穩，通常與學習率過高有關。,
L3QA141,S,以下哪一個 Optimizer 同時結合了動量（Momentum）與 RMSProp 的特性？,SGD,Adam,RMSProp,L-BFGS,2,Adam 內部同時使用一階動量與梯度平方移動平均，因此具備兩者優點。,
L3QA142,S,你在訓練一個深度神經網路，觀察到訓練集 loss 不斷下降但驗證集 loss 卻在上升。此時哪個做法最適合？,增加學習率,更換優化器,套用 Early Stopping,加入更多隱藏層,3,驗證集 loss 上升表示 overfitting，Early Stopping 可以避免過度學習。,
L3QA143,S,若某次迭代的梯度為 gt=0.5，學習率為 α=0.1，使用 SGD 更新參數的步伐為？,0.05,0.1,0.5,5.0,1,步伐為 α?gt=0.1?0.5=0.05,
L3QA144,S,以下哪一種 Learning Rate Scheduling 策略會根據 validation loss 停止改善而自動調降學習率？,Step Decay,Cyclical Learning Rate,Warm-up,ReduceLROnPlateau,4,ReduceLROnPlateau 是根據驗證集表現動態調整學習率。,
L3QA145,S,在以下哪種情境下 RMSProp 通常比 SGD 表現更佳？,小型線性回歸問題,非平穩梯度的深度網路訓練,決策樹建模,特徵選擇階段,2,RMSProp 特別適合非平穩目標，如 RNN、深層網路訓練等。,
L3QA146,S,若使用固定學習率 α=0.1，發現模型 loss 在訓練初期下降迅速，但後期停滯不前，最佳策略是？,提高學習率,改用正則化,降低學習率,增加訓練次數,3,初期學習率大可快速靠近，但後期應降低步伐以穩定微調。,
L3QA147,S,Adam Optimizer 中的 β1 和 β2 代表什麼？,兩組資料標準差,動量與梯度平方的衰減率,激活函數的門檻值,損失函數的權重系數,2,β1 控制一階動量，β2 控制梯度平方的平均，是 Adam 的關鍵設計。,
L3QA148,S,哪一種情況最有可能導致參數更新過快導致模型性能下降？,梯度太小,梯度為零,學習率太高,使用 L2 正則化,3,學習率太高會導致步伐過大，參數更新不穩定，甚至越來越遠離最小值。,
L3QA149,S,你正在訓練一個分類模型，但發現訓練資料準確率為 98%，測試資料僅為 70%。這最可能是哪個問題？ 欠擬合,,資料不夠,過擬合,模型過簡,3,訓練表現良好但測試表現差，典型的過擬合現象。可嘗試正則化或使用更少特徵。,
L3QA150,S,以下哪一種演算法屬於非監督式學習？,邏輯迴歸,決策樹,K-Means,隨機森林,3,K-Means 是用來進行分群，不需要標籤，是典型的非監督式學習方法。,
L3QA151,S,哪一個不是梯度下降法的變形？,SGD,Adam,Momentum,Q-Learning,4,Q-Learning 屬於強化學習方法，與梯度下降無關；其餘三個是優化器的變形。,
L3QA152,S,在神經網路中，使用哪種技巧可以防止過擬合？,增加神經元數量,加快學習率,Dropout,減少訓練次數,3,Dropout 是常用的正則化技術，可隨機關閉神經元，避免模型過度依賴特定特徵。,
L3QA153,S,若你要評估一個二元分類模型對「假陽性」與「假陰性」的綜合表現，應使用哪一指標？,Accuracy,Precision,Recall,F1-score,4,F1-score 是 Precision 和 Recall 的調和平均，適合處理類別不平衡問題的整體評估。,
L3QA154,S,以下哪種模型最適合解決迴歸問題？,隨機森林,KNN,線性迴歸,邏輯迴歸,3,線性迴歸是針對連續數值預測的經典方法。邏輯迴歸是分類用。,
L3QA155,S,哪一個步驟最可能發生在資料前處理階段？,損失函數最小化,模型訓練,標準化與缺值處理,選擇超參數,3,資料標準化（如 Z-score）與缺失值填補是前處理核心內容，應於模型訓練前完成。,
L3QA156,S,在主成分分析（PCA）中，主要目的是？,增強模型解釋力,進行特徵選擇,分類資料,降低資料維度,4,PCA 將高維資料轉換為低維表示，以保留最大變異資訊，是降維工具。,
L3QA157,S,哪一個選項是隨機森林相較於單一決策樹的主要優點？,模型較簡單,不需調整參數,抗雜訊能力強,絕對不會過擬合,3,隨機森林透過多棵樹平均結果，降低過擬合機率、提高泛化能力，但不能保證完全不過擬。,
L3QA158,S,你設計了一個多分類模型，想檢查其整體預測精度，應查看哪個指標？,MSE,R?,Accuracy,ROC AUC,3,Accuracy 是用於分類任務的整體準確率，適合用來觀察模型整體分類正確比例,
L3QA159,S,若你想將 100 維資料壓縮成 2 維進行視覺化，應用哪種方法？,K-Means,邏輯迴歸,PCA,神經網路,3,PCA（主成分分析）是降維常用方法。,
L3QA160,S,線性回歸模型中，下列哪一種情況最可能導致過擬合？,使用過多特徵變數,資料點過少但特徵很簡單,使用正則化技術,移除偏差項 b,1,過多特徵會使模型過度擬合訓練資料，失去泛化能力。正則化是為了解決過擬合，移除 b可能導致模型欠擬合。,
L3QA161,S,某間銀行利用決策樹進行貸款風險預測，模型效果不佳且過度複雜，該如何改善？,增加訓練資料,使用剪枝技術,移除所有類別型特徵,使用 k-means 聚類法,2,決策樹常因深度太大而過擬合，使用剪枝（Pruning）技術可控制樹的複雜度。,
L3QA162,S,以下哪個演算法不需訓練階段，而是直接在預測時使用資料？,隨機森林,SVM,k-NN,邏輯回歸,3,k-NN 屬於「懶惰學習」法，沒有訓練階段，預測時才進行比對。,
L3QA163,S,在處理維度極高的文本資料時，最適合使用哪種演算法？,k-NN,Naive Bayes,決策樹,線性回歸,2,Naive Bayes 在處理高維稀疏資料（如文字分類）效果很好，並假設特徵獨立。,
L3QA164,S,某公司將使用 SVM 進行商品分類，發現資料中出現錯誤標記。哪項技術有助於模型仍有良好表現？,選擇線性核,設定軟邊界（Soft Margin）,使用 PCA,將資料離散化,2,軟邊界允許 SVM 忍受部分分類錯誤，是應對少量噪音資料的方式。,
L3QA165,S,使用 k-means 分群時，群數 k 的設定錯誤會造成什麼影響？,增加訓練時間但不影響結果,造成模型過擬合,分群結果不具代表性,模型無法收斂,3,k 值設錯會導致分群不準確，無法有效代表真實群體結構。,
L3QA166,S,當特徵間具有高度共線性時，哪種模型會受到最明顯的影響？,線性回歸,隨機森林,k-NN,決策樹,1,線性回歸假設特徵獨立，共線性會導致估計不穩定，需配合正則化處理。,
L3QA167,S,某工廠採用隨機森林進行瑕疵偵測，主要原因為？,計算量小,易於視覺化解釋,不需參數設定,可避免單棵樹的過擬合問題,4,隨機森林是集成學習方法，透過多棵樹平均或投票，可降低單一樹過擬合的風險。,
L3QA168,S,關於神經網路的敘述，何者正確？,不適合處理非線性問題,層數愈多訓練愈快,需要大量資料與運算資源,完全無法解釋模型行為,3,神經網路擅長處理非線性問題，但訓練需大量資料與高運算資源；雖然可解釋性差，但並非完全無法理解。,
L3QA169,S,若使用主成分分析（PCA）處理資料，可達成下列哪一項？,增加分類精度,強化特徵間關聯性,降低維度，保留主要變異資訊,增加樣本數,3,PCA 是降維技術，將高維資料轉換為少數主成分，保留最大變異性。,
L3QA170,S,哪一個激活函數最容易導致梯度消失問題？,ReLU,Tanh,Sigmoid,Softmax,3,Sigmoid 在極端輸入值下導數趨近於 0，容易造成梯度消失。,
L3QA171,S,深度學習中，哪一個步驟主要負責調整權重以降低損失？,前向傳播,激活函數,損失函數計算,反向傳播,4,反向傳播運用鏈式法則計算梯度並調整權重。,
L3QA172,S,下列哪一項是 CNN 中負責降低參數數量的技術？,Dropout,Padding,Pooling,Batch Normalization,3,Pooling 可降低空間維度與參數量。,
L3QA173,S,哪一個不是 LSTM 的核心組件？,遺忘閘（Forget gate）,記憶閘（Memory gate）,輸出閘（Output gate）,輸入閘（Input gate）,2,LSTM 有三個主要閘門：輸入、遺忘、輸出，沒有「記憶閘」。,
L3QA174,S,哪個框架以「動態圖」建構為特色？,TensorFlow,Theano,PyTorch,MXNet,3,PyTorch 使用動態計算圖，執行即建圖，適合研究。,
L3QA175,S,以下哪個技術能有效減少過擬合？,激活函數,捲積層,Dropout,損失函數,3,Dropout 隨機關閉神經元，防止模型過擬合。,
L3QA176,S,GAN 的訓練包含兩個主要網路，分別是？,卷積網路與全連接網路,預測網與分析網,生成器與鑑別器,編碼器與解碼器,3,生成器負責產生資料，鑑別器判斷真假。,
L3QA177,S,Transformer 模型中，哪個機制使模型能捕捉長距離依賴？,Pooling,Self-Attention,Dropout,全連接層,2,Self-Attention 可以關注序列中任意位置。,
L3QA178,S,下列哪個是「前向傳播」的主要任務？,計算梯度,更新參數,預測輸出,測試準確率,3,前向傳播將輸入傳至輸出層得到預測結果。,
L3QA179,S,在 Keras 中訓練模型時，哪一個函數負責開始訓練？,compile(),fit(),predict(),evaluate(),2,fit() 是開始訓練模型的函數。,
L3QA180,S,下列哪種特徵工程方法最適合處理偏態分佈的連續數值資料？,One-Hot Encoding,Z-score 標準化,Log Transform,Label Encoding,3,對數轉換可有效降低右偏或左偏分佈的偏態程度，使資料更接近常態分佈，適合用於像收入、點擊數這類偏態資料。,
L3QA181,S,當類別型特徵為「產品大小（小、中、大）」時，最適合使用的編碼方式為？,One-Hot Encoding,Embedding,Hash Encoding,Label Encoding,4,此為有序類別（ordinal），Label Encoding 能保留順序資訊，One-Hot 則會忽略這種大小關係。,
L3QA182,S,下列哪種編碼技術最適合處理類別數極多（如幾千個用戶ID）的資料？,One-Hot Encoding,Target Encoding,Hashing Encoding,Label Encoding,3,Hashing Encoding 可固定輸出維度且不需儲存字典，適合高基數類別；One-Hot 在類別過多時會造成維度爆炸。,
L3QA183,S,下列關於 PCA 的敘述何者正確？,可直接應用於分類任務,是監督式學習,計算方式依賴標籤分佈,將資料投影到變異性最大方向,4,PCA 是非監督式學習，找出資料總變異性最大的方向進行投影，與標籤無關。,
L3QA184,S,下列關於 LDA 的描述何者為真？,可用於無標籤資料,是非監督式學習方法,最多可投影為原始特徵數維,投影方向為最大化類別可分性,4,LDA 為監督式降維方法，目的是強化類別區別性，最多只能降至 C?1 維。,
L3QA185,S,若想將 100 維原始特徵降維為 2 維進行可視化處理，且資料無標籤，最適方法是？,LDA,PCA,Target Encoding,Label Encoding,2,PCA 是非監督方法，不需標籤即可進行降維與可視化。 LDA 為監督式降維方法，目的是強化類別區別性，最多只能降至99( 100?1) 維。,
L3QA186,S,在實務中，Target Encoding 的最大風險是什麼？,資料維度太高,雜湊碰撞,預測值會失真,容易過擬合,4,Target Encoding 直接使用目標變數的平均值編碼類別，容易導致模型「記住答案」，尤其類別樣本太少時。,
L3QA187,S,下面哪一項情境最適合使用 Embedding 技術？,少量類別（例如性別）,經濟指標的正規化,深度學習中的商品類別向量化,Label Encoding 預處理,3,Embedding 是將高基數類別（如商品、地區、用戶）轉換為稠密向量，常用於深度學習與推薦系統。,
L3QA188,S,在使用 LDA 進行投影後，若有 3 個類別，最多可降維成幾維？,1,2,3,4,2,LDA 的最大維度為 C?1，C 為類別數，因此 3 類別可投影到 2 維。,
L3QA189,S,下列何者是 One-Hot Encoding 最可能的缺點？,模型無法處理數值,維度太低,引入順序誤解,資料稀疏且維度爆炸,4,One-Hot 會為每個類別建立一個欄位，若類別數太多會導致特徵數量大量增加，導致計算負擔加重與資料稀疏。,
L3QA190,S,在預處理類別型資料時，哪種編碼方法較適合無序類別資料？,Label Encoding,One-Hot Encoding,Standardization,PCA,2,無序類別應避免引入排序偏誤，故使用 One-Hot Encoding 為佳。,
L3QA191,S,某企業的資料樣本量不大，但主管要求模型必須可解釋與易於視覺化決策邏輯，最合適的模型為？,Support Vector Machine (SVM),Decision Tree,Deep Neural Network,XGBoost,2,此題考資料特性與可解釋性需求。Decision Tree 模型具有高度可視化特性（如繪圖呈現分支邏輯），可說明每次決策依據，適合小樣本且重視解釋的任務。,
L3QA192,S,下列哪一個做法最能有效防止深度學習模型過擬合？,增加學習率,移除所有 Dropout,增加模型層數,加入 Dropout 層,4,Dropout 是防止神經網路過擬合的常用技巧，在訓練時隨機忽略部分神經元，可增加模型泛化能力。A、B、C 反而會導致收斂不穩或模型過複雜。,
L3QA193,S,若任務為「大量特徵但樣本稀疏」，例如文字分類，最合適初步建模的技術是？,CNN,SVM with Kernel,Random Forest,Logistic Regression,2,高維稀疏資料（如 TF-IDF 編碼的文字）常見於文字分析。SVM 搭配核函數（kernel trick）可有效處理高維資料並找出非線性分類邊界。,
L3QA194,S,以下哪一項最能有效衡量二元分類模型在類別不平衡情況下的表現？,Accuracy,Recall,AUC (Area Under Curve),RMSE,3,Accuracy 易在不平衡資料下失真，AUC 可衡量模型在不同閾值下的整體分類能力，對正負類預測平衡性較佳。,
L3QA195,S,下列哪一個元件屬於深度學習模型中防止梯度消失的關鍵設計？,Sigmoid Activation,ReLU Activation,Softmax,MSE Loss,2,ReLU 函數在正區間有常數梯度，可減少深層網路中的梯度消失問題。相較之下，Sigmoid 在極值處導數趨近於 0，容易出現梯度消失。,
L3QA196,S,若模型表現良好於訓練集，但在驗證集表現很差，最可能的問題為？,欠擬合,過擬合,模型太簡單,樣本太少無法學習,2,訓練集好但驗證集差，代表模型在訓練資料上過度擬合（記憶而非學習），泛化能力不足，需考慮正則化、Dropout 或更換模型。,
L3QA197,S,在選擇模型時，若考量「效能穩定」與「預測結果整合」，下列哪一種方法較合適？,單一 Decision Tree,單一 Logistic Regression,Bagging（如隨機森林）,卷積神經網路（CNN）,3,Bagging 是集成學習的一種，透過多模型平均可降低變異與過擬合，提升穩定性與泛化能力。常見如 Random Forest。,
L3QA198,S,若模型出現欠擬合現象，下列哪一個調整方式最不合適？,增加模型複雜度,增加訓練資料量,加強特徵工程,增加正則化強度,4,欠擬合代表模型學習能力不足。增加正則化（如 L2）反而會進一步限制模型學習能力，應考慮放寬限制或改用更複雜模型。,
L3QA199,S,某影像辨識任務需快速部署並且即時預測，下列哪一種設計最合適？,使用大型 CNN 模型,使用簡化的 CNN 或 MobileNet,使用 SVM,使用多層 LSTM,2,MobileNet 為輕量級卷積神經網路，設計上考量效能與速度，適合行動裝置或需要即時性服務的應用場景。,
L3QA200,S,模型選擇流程的正確順序為何？,資料分析 → 模型優化 → 問題定義 → 模型選擇,模型建立 → 模型比較 → 問題定義 → 特徵工程,問題定義 → 資料理解 → 建立基準模型 → 模型比較 → 最終調整,特徵處理 → 評估指標 → 模型選擇 → 問題定義,3,模型選擇需依邏輯流程進行：從問題定義開始，先分析資料，再用 baseline 模型作比較，再進行模型調整，流程有系統性。,
L3QA201,S,在訓練一個回歸模型時，若使用的是 均方誤差（MSE） 作為損失函數，其主要特性為何？,抗離群值能力強,對誤差大小不敏感,會加大大誤差的懲罰,不適用於連續型標籤,3,MSE 計算平方誤差，誤差越大對損失貢獻越高，因此會強烈懲罰大誤差 → 對離群值敏感。,
L3QA202,S,研究員小明在資料量有限的情況下，欲評估模型穩定性與泛化能力，他應該採用哪種驗證方式？,Hold-Out 法,LOOCV,Grid Search,Bootstrap,2,Leave-One-Out Cross Validation（LOOCV）適合資料筆數少的情況，能充分使用資料，但計算量大。,
L3QA203,S,當模型參數空間龐大，且訓練時間有限時，以下哪種參數搜尋方法最適合？,Grid Search,Random Search,全域最佳解搜尋,梯度下降,2,隨機搜尋可避免遍歷整個空間，常在高維空間中有效找到近似最佳解，比 Grid Search 更有效率。,
L3QA204,S,某模型用於疾病偵測，資料中患者為少數類別，應優先考慮哪個評估指標？,Accuracy,Precision,Recall,F1-score,4,在類別不平衡問題中，F1-score 綜合了 precision 與 recall，能平衡看待漏報與誤報問題。,
L3QA205,S,模型在訓練資料上的準確率為 98%，測試資料上只有 75%，這種情況稱為：,欠擬合,資料異常,正常模型收斂,過擬合,4,訓練集表現極好，但測試集明顯差，表示模型記住了訓練資料 → 過擬合現象。,
L3QA206,S,以下哪一項屬於模型的「超參數（Hyperparameter）」？,線性模型中的權重,決策樹的深度,神經網路學到的權重,模型預測的結果,2,模型訓練前需設定的控制變數屬於超參數，如樹深、K值等；訓練中學得的是參數。,
L3QA207,S,某分類模型有極高 Precision，但 Recall 明顯偏低，此模型可能傾向：,亂猜類別,偏好預測為負類,常錯過正類（漏報）,模型無效,3,高 Precision 表示預測為正類時多為正確，但 Recall 低代表很多實際正類沒被偵測出來 → 漏報。,
L3QA208,S,下列哪一項主要用於減少模型對資料切分的敏感度，提升模型評估的穩定性？,Feature Scaling,Mini-batch 訓練,K-Fold Cross Validation,Feature Selection,3,K-fold 能讓每筆資料都有機會做驗證，能平衡偏差，提高評估穩定度。,
L3QA209,S,Early Stopping 的主要目的是：,加速訓練過程,讓模型預測更快,減少模型記憶體佔用,避免過度訓練導致過擬合,4,Early Stopping 在驗證集表現惡化時提早停止訓練，是常見防止過擬合策略。,
L3QA210,S,若一模型在訓練資料與測試資料上表現都很差，最可能原因為：,模型過擬合,模型欠擬合,超參數選得太好,訓練資料太多,2,訓練測試都表現差，代表模型學不到有效模式 → 欠擬合，應增加模型複雜度或改善特徵。,
L3QA211,S,你使用隨機森林模型預測客戶是否會流失，在交叉驗證結果中發現模型訓練準確率高達 98%，但測試資料僅有 74%。下列哪一項最可能改善此問題？,增加模型複雜度,減少訓練資料量,使用正則化方法,移除交叉驗證,3,訓練集表現很好但測試集明顯下降，顯示過擬合。正則化可抑制模型過度學習訓練資料，有助提升泛化能力。,
L3QA212,S,你想用 Grid Search 對支持向量機（SVM）進行超參數調整，以下哪組參數是正確的選擇？,learning_rate、batch_size,C、kernel、gamma,alpha、lambda,depth、leaf_nodes,2,SVM 調參主要針對 C（懲罰係數）、kernel（核函數類型）與 gamma（核函數參數）。,
L3QA213,S,在模型訓練過程中加入 Early Stopping 主要是為了：,增加訓練資料量,改善資料品質,防止過擬合,減少預測時間,3,Early Stopping 是在驗證集誤差開始上升時提前停止訓練，以防止模型在訓練集過度擬合。,
L3QA214,S,下列哪一個屬於非學習到的參數（Hyperparameter）？,神經網路中的權重,線性回歸的斜率,隨機森林的樹數量（n_estimators）,邏輯回歸的模型截距,3,n_estimators 是訓練前設定的超參數；其他都是透過訓練學到的模型參數。,
L3QA215,S,當使用 PCA 降維時，其主要目的為：,移除異常值,增加模型深度,提高模型複雜度,減少特徵數以避免過擬合,4,PCA 是降維技術，可降低特徵維度，減少計算成本，降低過擬合機率。,
L3QA216,S,你使用 Grid Search 調整模型參數時發現花費時間太久，以下哪個方法最適合改善效率？,使用更多參數,改用 Random Search,減少交叉驗證次數,使用原始資料作測試集,2,Random Search 比 Grid Search 更有效率，能在較短時間內找到近似最佳參數。,
L3QA217,S,以下哪個情況最可能導致欠擬合？,模型訓練太久,模型太複雜,模型太簡單或特徵不足,使用 Dropout,3,欠擬合通常是模型太簡單、特徵不夠或學習不足導致，無法擬合數據特徵。,
L3QA218,S,下列哪一項是 L2 正則化的主要效果？,完全移除不重要特徵,增加模型的非線性能力,壓抑大權重值,增加模型可解釋性,3,L2 透過平方懲罰抑制模型中出現過大的權重，幫助防止過擬合。,
L3QA219,S,你發現某模型在某些資料集上表現不穩定，每次訓練結果差異很大，最可能的解決方法是？,使用正則化,增加特徵數量,固定隨機種子（random_state）,移除測試集,3,每次結果不同表示訓練過程有隨機性，設定 random_state 可保證重複性與穩定性。,
L3QA220,S,你在使用神經網路時希望提升泛化能力且避免過擬合，以下哪個方法最適合？,調高學習率,增加訓練週期,使用 Dropout 技術,使用更多輸出神經元,3,Dropout 隨機屏蔽神經元，可強化模型泛化能力，降低過擬合。,
L3QA221,S,某家電信公司欲分析用戶通話時間趨勢，並宣稱使用差分隱私保護個資。以下哪項最可能是差分隱私的實作方式？,將所有資料加密儲存於資料庫,為每筆通話時間加入隨機噪音再進行統計分析,將所有資料匿名化並儲存在本地端,將結果以 PDF 匯出供分析人員使用,2,差分隱私透過在查詢結果中加入隨機噪音，使得單一資料對統計結果影響極小，B 是其核心作法。,
L3QA222,S,關於 AES 與 RSA 的敘述，下列何者正確？,AES 使用非對稱加密，適合用於金鑰交換,RSA 使用對稱加密，速度快,AES 為對稱加密，適合大量資料加密,RSA 適合用於資料壓縮與傳輸,3,AES 屬於對稱式加密，速度快、適合處理大量資料；RSA 為非對稱式加密，計算較慢，常用於金鑰交換與數位簽章。,
L3QA223,S,在 HTTPS 安全通訊中，RSA 加密技術主要負責哪一項功能？,為每個封包加密內容,傳送對稱加密用的金鑰,確保壓縮演算法正確執行,驗證使用者登入身份,2,實務上 HTTPS 採「混合加密」：RSA 傳遞 AES 金鑰，再由 AES 處理大量資料的加解密。,
L3QA224,S,若某公司聲稱其資料「去識別化」處理後已無隱私風險，以下哪項敘述正確？,去識別化資料無法還原，因此完全安全,去識別化等同匿名化，無須再加保護措施,去識別化仍可能被重建個資，應結合其他技術保護,去識別化後資料無須符合法規規範,3,去識別化移除直接辨識資料，但若與其他資料比對仍可能被重識別，因此需搭配差分隱私或其他技術。,
L3QA225,S,某企業在處理歐洲用戶的數據時，必須允許用戶要求系統永久刪除其資料。這項要求屬於哪一項 GDPR 原則？,資料最小化原則,資料可攜性原則,被遺忘權（Right to be Forgotten）,同意撤回原則,3,GDPR 中的「被遺忘權」允許個人要求刪除其個資，特別是在不再具有合法處理依據時。,
L3QA226,S,某公司訓練了一個 AI 模型來預測健康風險。攻擊者試圖從模型中還原某筆訓練資料。為了防止此類攻擊，以下哪種技術最適合使用？,匿名化資料,區塊鏈紀錄來源,差分隱私保護訓練過程,把模型設定為只讀不可修改,3,差分隱私能防止模型洩漏訓練資料，即使模型被分析也無法推回個人資訊。,
L3QA227,S,哪一項是企業常用的國際資訊安全管理標準？,GDPR,CCPA,ISO/IEC 27001,NIST 800-53,3,ISO/IEC 27001 是資訊安全管理系統（ISMS）標準，適用於組織建立、執行與持續改善資安策略。,
L3QA228,S,公司使用 AES 進行大規模資料加密，但工程師發現光靠對稱金鑰難以安全傳輸。以下哪種作法最可行？,增加 AES 金鑰長度,搭配 RSA 將 AES 金鑰加密傳輸,改用 DES 加密降低風險,將金鑰直接寫入模型參數中儲存,2,對稱式加密金鑰無法安全交換時，應使用非對稱加密（如 RSA）來傳遞金鑰，稱為混合加密。,
L3QA229,S,根據台灣個資法，機關若要蒐集個人資料，以下哪項最基本原則必須遵守？,資料須經主管機關認可,明確告知蒐集目的與使用方式,蒐集後應立即加密處理,僅可蒐集身份證與電話號碼,2,台灣個資法與 GDPR 一樣，強調資料蒐集須合法且明確告知目的，並取得使用者同意。,
L3QA230,S,以下哪種加密方法屬於非對稱加密？,AES,RSA,DES,SHA-256（雜湊非加密）,2,,
L3QA231,S,在 HTTPS 加密中，RSA 主要用途為？,傳輸主要資料,傳送對稱式金鑰,建立雙向信道,驗證網站圖像,2,,
L3QA232,S,差分隱私主要目的為？,資料壓縮,模型準確度提升,降低資料儲存成本,保護個人資料不被推斷,4,,
L3QA233,S,下列哪一種方法最常用於差分隱私數值資料？,RSA加密,拉普拉斯機制,決策樹,均值移動,2,,
L3QA234,S,在差分隱私中 ε 越大代表：,噪音越多，隱私保護越強,噪音越少，隱私保護越弱,無法推論,系統錯誤越大,2,,
L3QA235,S,某銀行使用機器學習模型預測貸款違約風險，結果顯示相同信用條件下，某少數族群的核貸率明顯較低。此現象最可能屬於哪一種偏見？,樣本偏見,測量偏見,歷史偏見,模型偏見,3,此為過去歷史資料中就存在的偏見（如制度性歧視），模型只是延續了這種模式。,
L3QA236,S,為了避免模型對特定年齡族群產生偏誤，企業在訓練資料中將年齡欄位刪除。此方法屬於哪一類偏見緩解技術？,資料重加權,去敏感特徵處理（Fair Representation）,模型後處理,對抗式學習,2,這是典型的資料前處理方法，透過移除敏感屬性來減少潛在偏見。,
L3QA237,S,某模型的預測結果顯示男性與女性中皆有相同比例的真陽性率（True Positive Rate），但錯誤率不同。這代表模型未達成哪一種公平性？,Equalized Odds,Predictive Parity,Equal Opportunity,Individual Fairness,1,Equalized Odds 要求 TP 和 FP 在各群體都一致，此案例錯誤率不同，因此未滿足。,
L3QA238,S,在實務應用中，何者不屬於公平性評估指標？,Equal Opportunity,Individual Fairness,RMSE（均方根誤差）,Predictive Parity,3,RMSE 是效能評估指標，不是公平性相關指標。,
L3QA239,S,某保險公司 AI 系統在預測風險時，發現模型對年長者的錯誤預測比例遠高於年輕人。若欲改善此情況，以下哪一方法最適合？,使用更複雜的深度學習架構,增加年輕人樣本數量,設計後處理調整預測閾值,排除所有年齡相關欄位,3,屬於後處理技術，透過調整各群體的決策閾值來補平偏誤。,
L3QA240,S,若模型對不同種族族群的 Precision 一致，則滿足下列哪種公平性？,Demographic Parity,Predictive Parity,Equalized Odds,Equal Opportunity,2,Predictive Parity 關注的是預測為正時的準確率（Precision）在各群體一致。,
L3QA241,S,某演算法的公平性檢測發現，不同性別在預測結果為正例的機率差異很大，但 TP 和 FN 差不多。這代表下列哪項未達標？,Predictive Parity,Equalized Odds,Equal Opportunity,Demographic Parity,4,Demographic Parity 關注的是「不看真實標籤」，正例預測在不同群體比例是否一致。,
L3QA242,S,某公司針對 AI 決策進行公平性分析，將兩位特質幾乎一樣的使用者送入模型，卻得出不同結果，違反了哪項原則？,Equal Opportunity,Individual Fairness,Group Fairness,Sampling Bias,2,Individual Fairness 強調相似的人應得相似的預測結果。,
L3QA243,S,關於公平性處理方法，下列敘述何者正確？,模型內調整是在訓練完成後對輸出做修改,去偏見只能靠資料清洗處理,Adversarial Debiasing 屬於模型內處理方法,Fairness by Design 是指產品 UI 設計公平性,3,對抗式去偏技術（Adversarial Debiasing） 是一種內部模型訓練中引入公平性限制的方法。,
L3QA244,S,關於公平性與準確性間的關係，下列敘述錯誤的是？,公平性要求可能會降低模型的總體準確率,模型公平性與效能可透過權衡達成,若模型準確率高，表示必定公平,不同公平性指標可能互相衝突,3,高準確率不代表公平，例如模型可能準確地預測出偏誤結果給某族群。,
