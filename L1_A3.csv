題號,難度,題目,選項 1,選項 2,選項 3,選項 4,正確答案,正確答案解說,錯誤答案解說
L13Q262,S,在設計高度模組化的 AI 系統時，哪一項技術最能有效支援鬆耦合並避免模組之間的直接依賴？,Redis 快取,Docker Compose,Kafka,TensorFlow Lite,3,Kafka 是一種訊息佇列系統，支援事件驅動架構，允許模組間非同步傳遞資料而不需直接呼叫，實現鬆耦合。,
L13Q263,S,若要確保系統發生單點故障時仍可提供服務，最佳的部署組合是？,GPU 優化 + 模型壓縮,單區多副本部署 + 快取機制,多區部署 + 負載平衡,FastAPI + Docker,3,多區部署可避免區域性故障導致全面癱瘓，搭配負載平衡器（如 Nginx）可自動引導流量至健康節點，是高可用性部署的核心作法。,
L13Q264,S,關於 FastAPI 與 gRPC 的選擇，下列敘述何者正確？,FastAPI 適合高效能跨服務通訊,gRPC 使用 JSON 格式進行傳輸,FastAPI 適合 RESTful API 開發，gRPC 適合內部微服務通訊,gRPC 不支援 Python 語言,3,FastAPI 屬於 RESTful 架構，簡單易用；gRPC 基於 Protobuf，效能高、適合內部微服務。,
L13Q265,S,哪一項是模型 Drift 的早期偵測機制？,Kubernetes readiness probe,MLflow version control,EvidentlyAI drift report,Prometheus 警報規則,3,EvidentlyAI 提供模型 drift 的統計檢測報告，可比較預測資料與訓練資料分布差異，偵測 concept drift。,
L13Q266,S,若系統需同時部署多個模型並支援 GPU 加速，以下何者最適合？,TorchServe,TensorFlow Lite,Flask,NVIDIA Triton,4,NVIDIA Triton 可同時支援多模型 GPU 推論，並支援 ONNX、TensorFlow、PyTorch 等框架，是多模型高效能部署首選。,
L13Q267,S,對於支援自動資源調度與模型部署擴縮容的最佳組合是？,Terraform + Docker,Kubernetes + HPA,MLflow + GitHub Actions,Kafka + REST API,2,Kubernetes 的 HPA 可根據 CPU/RAM/自定義指標自動擴縮容器，非常適合動態服務負載調整。,
L13Q268,S,某企業想導入 AI 系統並實現 IaC（Infrastructure as Code），最合適工具為？,Gradio,Prometheus,Terraform,HuggingFace Hub,3,Terraform 是專為 IaC 設計的工具，能以程式碼管理雲端資源配置，自動化部署。,
L13Q269,S,哪一項指標不適合用來判斷模型效能退化？,Accuracy,Drift,Loss,Docker CPU 使用率,4,CPU 使用率為基礎硬體資源指標，無法直接反映模型預測表現。,
L13Q270,S,若 AI 模型需頻繁呼叫且運行在 Serverless 架構中，為降低冷啟動延遲，最佳策略是？,增加 Lambda 記憶體,使用 Warm-up 機制預載執行環境,改用 REST API,切換至微服務架構,2,Serverless 架構常見問題為「cold start」，可透過預熱請求（warm-up）讓容器維持活躍狀態以避免延遲。,
L13Q271,S,模型服務部署在容器後，若需監控其存活狀況與回應健康，應採用何技術？,FastAPI metrics,Kubernetes liveness/readiness probe,Docker stats,Flask debug mode,2,Kubernetes 內建的存活與就緒探針可定期確認容器是否可服務與健康，異常則自動重啟。,
L13Q272,S,若系統資料流由資料清洗 → 模型預測 → 儲存結果，最能實現模組鬆耦合的技術是？,Redis,RabbitMQ,PySpark,FastAPI,2,RabbitMQ 是實現模組間資料流非同步處理的常用工具，有助於鬆耦合與模組獨立部署。,
L13Q273,S,若需將模型部署於 IoT 裝置並儘量減少資源消耗，最佳作法是？,使用 ONNX Runtime,模型量化與剪枝後再進行邊緣部署,REST API 呼叫遠端模型,FastAPI 微服務封裝,2,IoT 裝置資源有限，需將模型壓縮至最小，量化與剪枝是常用的優化手段。,
L13Q274,S,若需自動化從資料清洗到模型部署的整合流程，應選用？,Grafana,Airflow,Gradio,Kibana,2,Apache Airflow 是業界標準的工作流程排程工具，可串聯整個 AI 管線流程。,
L13Q275,S,MLflow 的 tracking component 最主要用途為？,提供 GPU 加速,模型微調,記錄模型實驗與參數,整合 API 層,3,MLflow 的 tracking 是追蹤模型訓練歷程與效能的關鍵模組，有助於版本控制與重現性。,
L13Q276,S,下列哪項部署方式最適合處理模型間推論需求高、即時性強的情境？,Flask + Gunicorn,TensorFlow Lite,NVIDIA Triton + gRPC,Streamlit,3,NVIDIA Triton 能處理多模型 GPU 推論，gRPC 則提供低延遲通訊，是即時服務部署首選。,
L13Q277,S,若模型部署於 Google Vertex AI，以下哪個功能能簡化模型再訓練與部署流程？,AutoML pipeline,GCS blob 儲存,Kubeflow Pipelines,Cloud SQL,1,Vertex AI 的 AutoML pipeline 提供一站式 AI 開發流程，自動完成模型生命周期管理。,
L13Q278,S,若前端應用需與多個模型交互，且要求最低延遲，推薦使用哪種架構？,Flask 多執行緒 API,REST API 單一端點,gRPC 並行呼叫,React 串接 HTTP,3,gRPC 為高效能通訊協議，適合內部服務並行低延遲通訊，優於傳統 REST。,
L13Q279,S,在使用 Prometheus + Grafana 監控部署系統時，若想追蹤模型輸出延遲，應如何設定？,設定 FastAPI 路由緩存,利用中介層紀錄 inference latency 並暴露為 metric,用 MLflow 記錄日誌,Docker Compose 加入 volume 映射,2,部署中常透過中介層實作延遲測量並輸出為自訂 metrics 供 Prometheus 抓取，Grafana 可視覺化。,
L13Q280,S,若希望避免服務中斷，在進行模型更新部署時應選用？,滾動更新（Rolling Update）,停機部署,模型壓縮,模型剪枝,1,滾動更新是 CI/CD 中常見部署方式，保留部分舊實例確保穩定性。,
L13Q281,S,在進行整合測試時，應確認哪一項？,單一模組內部函式正確性,多模組間資料傳遞與依賴邏輯,模型效能指標是否達標,模型檔案大小是否壓縮,2,整合測試聚焦在系統模組之間的互動與資料流傳遞的正確性。,